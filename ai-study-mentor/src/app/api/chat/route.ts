import { NextRequest, NextResponse } from "next/server";
import { verifyToken } from "@/lib/jwt";
import { searchSimilarDocuments } from "@/lib/pinecone";
import { generateEmbeddings } from "@/lib/documentProcessor";
import { connectDB } from "@/lib/db";
import { ChatSession } from "@/models/ChatSession";

export async function POST(request: NextRequest) {
  try {
    // Verifiera JWT token (fr√•n header eller cookies)
    const token =
      request.headers.get("authorization")?.replace("Bearer ", "") ||
      request.cookies.get("auth-token")?.value;

    console.log("üí¨ Chat API anropad, token finns:", !!token);

    if (!token) {
      return NextResponse.json(
        { error: "Ingen autentisering angiven" },
        { status: 401 }
      );
    }

    const user = verifyToken(token);
    if (!user) {
      return NextResponse.json({ error: "Ogiltig token" }, { status: 401 });
    }

    // H√§mta fr√•gan fr√•n request body
    const requestBody = await request.json();
    console.log("üìù Request body:", requestBody);

    const { message, conversationHistory = [], sessionId } = requestBody;
    console.log(
      "üí¨ Message:",
      message,
      "Type:",
      typeof message,
      "Length:",
      message?.length
    );

    if (
      !message ||
      typeof message !== "string" ||
      message.trim().length === 0
    ) {
      console.log("‚ùå Message validation failed");
      return NextResponse.json(
        { error: "Meddelande saknas eller √§r tomt" },
        { status: 400 }
      );
    }

    console.log(`ü§î Anv√§ndare ${user.userId} fr√•gar: "${message}"`);

    // Steg 1: Generera embedding f√∂r anv√§ndarfr√•gan
    console.log("üß† Genererar embedding f√∂r fr√•gan...");
    const questionEmbeddings = await generateEmbeddings([message.trim()]);
    const questionEmbedding = questionEmbeddings[0];

    // Steg 2: S√∂k liknande dokument i Pinecone
    console.log("üîç S√∂ker relevanta dokument...");
    const relevantDocuments = await searchSimilarDocuments(
      questionEmbedding,
      user.userId,
      5 // H√§mta top 5 mest relevanta chunks
    );

    if (relevantDocuments.length === 0) {
      return NextResponse.json({
        response:
          "Jag kunde inte hitta n√•got relevant inneh√•ll i dina uppladdade dokument f√∂r den fr√•gan. Prova att ladda upp mer material eller omformulera din fr√•ga.",
        sources: [],
        conversationId: `conv_${Date.now()}`,
      });
    }

    // Steg 3: F√∂rbered kontext f√∂r AI-modellen (begr√§nsa l√§ngd)
    const context = relevantDocuments
      .map(
        (doc, index) => `[K√§lla ${index + 1}]: ${doc.text.substring(0, 800)}...`
      ) // Begr√§nsa varje chunk till 800 tecken
      .join("\n\n");

    // Steg 4: Generera svar med Ollama
    console.log("ü§ñ Genererar AI-svar...");
    const aiResponse = await generateAIResponse(
      message,
      context,
      conversationHistory
    );

    // Steg 5: F√∂rbered k√§llor f√∂r frontend
    const sources = relevantDocuments.map((doc, index) => ({
      id: index + 1,
      text: doc.text.substring(0, 200) + (doc.text.length > 200 ? "..." : ""),
      score: doc.score,
      fileName: doc.fileName || "Ok√§nd k√§lla",
      chunkIndex: doc.chunkIndex || 0,
    }));

    // Steg 6: Spara konversation till databas
    await connectDB();

    let currentSession;
    let actualSessionId = sessionId;

    if (sessionId) {
      // Uppdatera befintlig session
      currentSession = await ChatSession.findById(sessionId);
      if (currentSession && currentSession.userId.toString() === user.userId) {
        currentSession.messages.push(
          {
            role: "user",
            content: message,
            timestamp: new Date(),
          },
          {
            role: "assistant",
            content: aiResponse,
            timestamp: new Date(),
          }
        );
        currentSession.updatedAt = new Date();
        await currentSession.save();
        actualSessionId = (currentSession._id as any).toString();
      }
    } else {
      // Skapa ny session (l√•t MongoDB generera _id automatiskt)
      const sessionTitle =
        message.substring(0, 50) + (message.length > 50 ? "..." : "");
      currentSession = new ChatSession({
        userId: user.userId,
        title: sessionTitle,
        messages: [
          {
            role: "user",
            content: message,
            timestamp: new Date(),
          },
          {
            role: "assistant",
            content: aiResponse,
            timestamp: new Date(),
          },
        ],
        createdAt: new Date(),
        updatedAt: new Date(),
      });
      await currentSession.save();
      actualSessionId = (currentSession._id as any).toString();
    }

    return NextResponse.json({
      response: aiResponse,
      sources,
      conversationId: actualSessionId,
      sessionId: actualSessionId,
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    console.error("Fel vid AI-chat:", error);

    return NextResponse.json(
      {
        error:
          "Ett fel uppstod vid bearbetning av din fr√•ga. F√∂rs√∂k igen senare.",
        details: error instanceof Error ? error.message : "Ok√§nt fel",
      },
      { status: 500 }
    );
  }
}

/**
 * Genererar AI-svar med hj√§lp av Ollama
 */
async function generateAIResponse(
  question: string,
  context: string,
  conversationHistory: Array<{ role: string; content: string }> = []
): Promise<string> {
  const ollamaBaseUrl = process.env.OLLAMA_BASE_URL || "http://localhost:11434";

  // Bygg konversationskontext
  let conversationContext = "";
  if (conversationHistory.length > 0) {
    conversationContext =
      "\nTidigare konversation:\n" +
      conversationHistory
        .slice(-4) // Bara de senaste 4 meddelandena f√∂r att h√•lla kontexten hanterbar
        .map((msg) => `${msg.role}: ${msg.content}`)
        .join("\n") +
      "\n";
  }

  const prompt = `Du √§r en hj√§lpsam AI-assistent som ger korta, tydliga svar p√• svenska baserat p√• tillhandah√•llen information.

${conversationContext}

Baserat p√• f√∂ljande information fr√•n anv√§ndarens dokument:

${context}

Fr√•ga: ${question}

Ge ett kort och precist svar p√• svenska (max 2-3 meningar) baserat p√• informationen ovan. Om informationen inte r√§cker, s√§g det tydligt.

Svar:`;

  try {
    console.log(
      "üöÄ Skickar request till Ollama:",
      `${ollamaBaseUrl}/api/generate`
    );

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 180000); // 3 minuter timeout

    const response = await fetch(`${ollamaBaseUrl}/api/generate`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      signal: controller.signal,
      body: JSON.stringify({
        model: "llama3.2:1b", // Mindre modell som passar i systemets minne (1.5GB vs 6GB)
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          num_predict: 200, // Minska f√∂r snabbare svar
        },
      }),
    });

    clearTimeout(timeoutId);

    console.log("üì° Ollama response status:", response.status);

    if (!response.ok) {
      const errorText = await response.text();
      console.log("‚ùå Ollama error response:", errorText);
      throw new Error(`Ollama API fel: ${response.status} - ${errorText}`);
    }

    const data = await response.json();

    if (!data.response) {
      throw new Error("Inget svar fr√•n Ollama");
    }

    return data.response.trim();
  } catch (error) {
    console.error("Fel vid AI-svar generering:", error);

    // Fallback till en enkel sammanfattning av kontexten
    return `Baserat p√• dina dokument kan jag se information om: ${context.substring(
      0,
      300
    )}... 

Jag har f√∂r n√§rvarande tekniska problem med AI-svars genereringen. Prova att omformulera din fr√•ga eller kontakta support om problemet kvarst√•r.`;
  }
}
