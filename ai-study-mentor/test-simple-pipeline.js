const { Pinecone } = require('@pinecone-database/pinecone');
const fs = require('fs');
require('dotenv').config({ path: '.env.local' });

async function testDocumentProcessingSimple() {
  console.log('üß™ Testar enkel dokumentprocessering och Ollama + Pinecone integration...');
  
  try {
    // Test 1: L√§s testfil
    console.log('üìÑ L√§ser testfil...');
    const testText = fs.readFileSync('test-dokument.txt', 'utf-8');
    console.log(`‚úÖ Fil l√§st: ${testText.length} tecken`);
    
    // Test 2: Skapa enkla chunks
    const chunks = testText.split('\n\n').filter(chunk => chunk.trim().length > 0);
    console.log(`üìù Skapade ${chunks.length} chunks`);
    
    // Test 3: Generera embeddings med Ollama
    console.log('ü¶ô Genererar embeddings med Ollama...');
    const ollamaUrl = 'http://localhost:11434';
    const embeddings = [];
    
    for (const [i, chunk] of chunks.entries()) {
      console.log(`   Bearbetar chunk ${i + 1}/${chunks.length}...`);
      
      const response = await fetch(`${ollamaUrl}/api/embeddings`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'nomic-embed-text',
          prompt: chunk.trim(),
        }),
      });

      if (!response.ok) {
        throw new Error(`Ollama fel: ${response.status}`);
      }

      const data = await response.json();
      embeddings.push(data.embedding);
    }
    
    console.log(`‚úÖ ${embeddings.length} embeddings genererade!`);
    console.log(`üìè Embedding dimensioner: ${embeddings[0].length}`);
    
    // Test 4: Ladda upp till Pinecone
    console.log('üìä Laddar upp till Pinecone...');
    
    const pc = new Pinecone({
      apiKey: process.env.PINECONE_API_KEY,
    });
    
    const index = pc.index('ai-study-mentor');
    
    // F√∂rbered vektorer
    const vectors = embeddings.map((embedding, i) => ({
      id: `test-${Date.now()}-${i}`,
      values: embedding,
      metadata: {
        text: chunks[i],
        source: 'test-pipeline',
        chunkIndex: i,
        timestamp: new Date().toISOString(),
      },
    }));
    
    await index.namespace('test-pipeline').upsert(vectors);
    
    console.log('‚úÖ Embeddings lagrade i Pinecone!');
    
    // Test 5: Test s√∂kning
    console.log('üîç Testar semantisk s√∂kning...');
    const searchQuery = 'Vad √§r artificiell intelligens?';
    
    // Generera embedding f√∂r s√∂kfr√•gan
    const searchResponse = await fetch(`${ollamaUrl}/api/embeddings`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'nomic-embed-text',
        prompt: searchQuery,
      }),
    });
    
    const searchData = await searchResponse.json();
    
    // S√∂k i Pinecone
    const searchResults = await index.namespace('test-pipeline').query({
      vector: searchData.embedding,
      topK: 3,
      includeMetadata: true,
    });
    
    console.log('üéØ S√∂kresultat:');
    searchResults.matches.forEach((match, i) => {
      console.log(`   ${i + 1}. Score: ${match.score.toFixed(4)}`);
      console.log(`      Text: "${match.metadata.text.substring(0, 100)}..."`);
    });
    
    // Rensa upp
    console.log('üßπ Rensar upp testdata...');
    const idsToDelete = vectors.map(v => v.id);
    await index.namespace('test-pipeline').deleteMany(idsToDelete);
    
    console.log('\nüéâ FULLST√ÑNDIG PIPELINE TEST LYCKAD!');
    console.log('‚úÖ Alla komponenter fungerar:');
    console.log('   ‚Ä¢ Text l√§sning och chunking');
    console.log('   ‚Ä¢ Ollama embedding generering');
    console.log('   ‚Ä¢ Pinecone vector lagring');
    console.log('   ‚Ä¢ Semantisk s√∂kning');
    console.log('   ‚Ä¢ Data cleanup');
    
  } catch (error) {
    console.error('‚ùå Pipeline test misslyckad:', error.message);
  }
}

testDocumentProcessingSimple();